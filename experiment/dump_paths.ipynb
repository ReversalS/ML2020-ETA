{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "e:\\Code\\ML2020-ETA\n"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要load进来一部分GPS数据，然后查找对应单号的，放到一起组成Path，然后dump\n",
    "\n",
    "先考虑完整路线，即可以包括多个“-”来连接路线，在GPS数据中是存在这类情况的\n",
    "\n",
    "可以先存单号，然后查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "15513\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# 先试试统计单号，真正遍历一趟全数据\n",
    "train_header = [\n",
    "    \"loadingOrder\",\n",
    "    \"carrierName\",\n",
    "    \"timestamp\",\n",
    "    \"longtitue\",\n",
    "    \"latitude\",\n",
    "    \"vesselMMSI\",\n",
    "    \"speed\",\n",
    "    \"direction\",\n",
    "    \"vesselNextport\",\n",
    "    \"vesselNextportETA\",\n",
    "    \"vesselStatus\",\n",
    "    \"vesselDatasource\",\n",
    "    \"TRANSPORT_TRACE\"\n",
    "]\n",
    "gps_record_reader = pd.read_csv('data/train0523.csv', header=None, low_memory=False, chunksize=1024 * 1024) # 读22G大数据集\n",
    "# gps_record_reader.columns = train_header  # set headers\n",
    "\n",
    "# # open pickle file\n",
    "# ordersets_file = open('data/ordersets', 'wb')\n",
    "# # create ordersets\n",
    "# for chunk in gps_record_reader:\n",
    "#     los = set()\n",
    "#     print('one chunk')\n",
    "#     for order in chunk[0]:\n",
    "#         los.add(order)\n",
    "#     pickle.dump(los, ordersets_file)\n",
    "# # close pickle file\n",
    "# ordersets_file.close()\n",
    "\n",
    "# longest/shortest path\n",
    "loading_order_event = pd.read_csv('data/loadingOrderEvent.csv', low_memory=False) # 辅助数据\n",
    "print(len(set(loading_order_event['loadingOrder'])))\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21157\npath finding process took 286.4367561340332\n"
    }
   ],
   "source": [
    "# # build order set\n",
    "# ordersets = []\n",
    "# orderset = set()\n",
    "# with open('data/ordersets', 'rb') as f:\n",
    "#     while True:\n",
    "#         try:\n",
    "#             ordersets.append(pickle.load(f))\n",
    "#         except:\n",
    "#             break\n",
    "# for s in ordersets:\n",
    "#     orderset = orderset | s\n",
    "# print(len(orderset))\n",
    "\n",
    "# gps_record_reader = pd.read_csv('data/train0523.csv', header=None, low_memory=False, chunksize=1024 * 1024) # 重新设置Reader指针\n",
    "# # find paths\n",
    "# start_time = time.time()\n",
    "# with open('data/path_mapping', 'wb') as f:\n",
    "#     path_mapping = {}\n",
    "#     count = 0\n",
    "#     for order in orderset:\n",
    "#         path_mapping[order] = []\n",
    "#     for chunk in gps_record_reader:\n",
    "#         for order in chunk[0]:\n",
    "#             path_mapping[order].append(count)\n",
    "#             count += 1\n",
    "#         # if count > 1024 * 1024 * 2 :\n",
    "#         #     break\n",
    "#     # print(path_mapping['ZQ464072113491'][:100])\n",
    "#     pickle.dump(path_mapping, f)\n",
    "# end_time = time.time()\n",
    "# print('path finding process took {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max path length: 287888\n"
    }
   ],
   "source": [
    "max_length = 0\n",
    "max_len_path = None\n",
    "for path in path_mapping.values():\n",
    "    if len(path) > max_length:\n",
    "        max_length = len(path)\n",
    "        max_len_path = path\n",
    "print('max path length:', max_length)\n",
    "# print('max length path:', max_len_path)\n",
    "# use path mappings, plot a path\n",
    "mlp_x = []\n",
    "mlp_y = []\n",
    "for i in max_len_path:\n",
    "    ref = gps_record_reader[3\n",
    "    mlp_x.append(ref[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max path length in test data: 1921\nmin path length in test data: 7\n"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/A_testData0531.csv', low_memory=False)\n",
    "max_length = 0\n",
    "min_length = 20000\n",
    "count = 0\n",
    "prev_order = None\n",
    "for order in test_data['loadingOrder']:\n",
    "    if order == prev_order:\n",
    "        count += 1\n",
    "    else:\n",
    "        if count > max_length:\n",
    "            max_length = count\n",
    "        elif count < min_length and count != 0:\n",
    "            min_length = count\n",
    "        count = 1\n",
    "        prev_order = order\n",
    "print('max path length in test data:', max_length)\n",
    "print('min path length in test data:', min_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittfenv20conda766c41579b2b4f15b06adf3d1d69eb2b",
   "display_name": "Python 3.7.7 64-bit ('tfenv20': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}