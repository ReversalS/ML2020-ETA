{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "e:\\Code\\ML2020-ETA\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, time, datetime\n",
    "os.chdir('..')\n",
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据的一些特征/分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OIEQNT    30395\nOYSCFP     5779\nJCMFTA     4641\nRWHZVZ     1823\nUQCRKD     1297\nBHSOUA      834\nVRFMKJ      657\nFXAJBJ       30\nName: carrierName, dtype: int64\n"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/A_testData0531.csv', low_memory=False)\n",
    "print(test_data['carrierName'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "B8664636040    5572\nC7827726749    4882\nS7020352560    3810\nX3806214427    2815\nU3534410038    1921\n               ... \nN9037513561      43\nQ4197827697      43\nM5147580600      38\nG9393704581      37\nU4075972506       7\nName: vesselMMSI, Length: 87, dtype: int64\n"
    }
   ],
   "source": [
    "print(test_data['vesselMMSI'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CNYTN-MXZLO    25685\nCNYTN-PAONX     5700\nCNSHK-CLVAP     2900\nCNYTN-ARENA     2833\nCNSHK-MYTPP     1855\nCNYTN-MATNG     1694\nCNSHK-GRPIR      721\nCNYTN-CAVAN      657\nCNHKG-MXZLO      613\nCNSHK-SGSIN      595\nCNYTN-RTM        357\nCNSHA-SGSIN      292\nCNSHK-SIKOP      266\nCOBUN-HKHKG      245\nHKHKG-FRFOS      223\nCNYTN-NZAKL      165\nCNSHK-ESALG      150\nCNSHK-ZADUR      150\nCNSHA-PAMIT      113\nCNSHK-PKQCT      104\nCNSHK-LBBEY       69\nCNYTN-MTMLA       69\nName: TRANSPORT_TRACE, dtype: int64\n"
    }
   ],
   "source": [
    "print(test_data['TRANSPORT_TRACE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据里面和测试数据关联的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CNSHK-ZADUR\nCNSHK-SGSIN\nCNHKG-MXZLO\nCNSHK-PKQCT\nCNYTN-MATNG\nCNSHK-CLVAP\nCNYTN-NZAKL\nCNYTN-MXZLO\nCNYTN-PAONX\nCOBUN-HKHKG\nCNYTN-RTM\nCNSHK-SIKOP\nCNYTN-MTMLA\nCNYTN-ARENA\nCNYTN-CAVAN\nCNSHA-PAMIT\nCNSHK-LBBEY\n{'CNSHK-MYTPP': 1855, 'CNSHK-GRPIR': 721, 'CNSHA-SGSIN': 292, 'HKHKG-FRFOS': 223, 'CNSHK-ESALG': 150}\n"
    }
   ],
   "source": [
    "trace_set = test_data['TRANSPORT_TRACE'].value_counts().to_dict()\n",
    "\n",
    "CHUNK_SIZE = 1024 * 1024\n",
    "gps_record_reader = pd.read_csv('data/train0523.csv', header=None, low_memory=False, chunksize=CHUNK_SIZE)\n",
    "for chunk in gps_record_reader:\n",
    "    for trace in chunk[12]:\n",
    "        if trace in trace_set:\n",
    "            print(trace)\n",
    "            del trace_set[trace]\n",
    "    if len(trace_set) == 0:\n",
    "        break\n",
    "print(trace_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['HKHKG', 'FRFOS'] ['HKHKG', 'FRFOS', 'FRMRS', 'TNTUN']\n['CNSHK', 'MYTPP'] ['CNSHK', 'MYTPP', 'MVMLE']\n['CNSHK', 'ESALG'] ['CNSHK', 'ESALG', 'MRNKC']\n['CNSHA', 'SGSIN'] ['CNSHA', 'SGSIN', 'OMSOH']\n['CNSHK', 'GRPIR'] ['CNSHK', 'MYTPP', 'MYPKG', 'EGSUZ', 'GRPIR', 'ILASH', 'ILHFA', 'TRMER', 'CYFMG']\n[]\n"
    }
   ],
   "source": [
    "indirect_trace = [x.split('-') for x in ['CNSHK-MYTPP', 'CNSHK-GRPIR', 'CNSHA-SGSIN', 'HKHKG-FRFOS', 'CNSHK-ESALG']]\n",
    "gps_record_reader = pd.read_csv('data/train0523.csv', header=None, low_memory=False, chunksize=CHUNK_SIZE)\n",
    "for chunk in gps_record_reader:\n",
    "    for trace in chunk[12]:\n",
    "        if pd.isna(trace):\n",
    "            continue\n",
    "        s_trace = trace.split('-')\n",
    "        for i, pair in enumerate(indirect_trace):\n",
    "            if pair[0] in s_trace and pair[1] in s_trace:\n",
    "                print(pair, s_trace)\n",
    "                del indirect_trace[i]\n",
    "    if indirect_trace == []:\n",
    "        break\n",
    "print(indirect_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出一部分数据\n",
    "\n",
    "缺失值真的不怎么好处理，但是这么筛下来还有3.19GB数据，足够了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nprocessed one chunk\nfinished data filtering\n"
    }
   ],
   "source": [
    "gps_record_reader = pd.read_csv('data/train0523.csv', header=None, low_memory=False, chunksize=CHUNK_SIZE)\n",
    "trace_set = test_data['TRANSPORT_TRACE'].value_counts().to_dict()\n",
    "trace_split_set = [x.split('-') for x in trace_set]\n",
    "\n",
    "try:\n",
    "    os.remove('data/filtered_data.csv')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "for chunk in gps_record_reader:\n",
    "    selected_indexes = []\n",
    "    for i, trace in enumerate(chunk[12]):\n",
    "        if pd.isna(trace):\n",
    "            continue\n",
    "        if trace in trace_set:\n",
    "            selected_indexes.append(i)\n",
    "        else:\n",
    "            s_trace = trace.split('-')\n",
    "            for pair in trace_split_set:\n",
    "                if pair[0] in s_trace and pair[1] in s_trace:\n",
    "                    selected_indexes.append(i)\n",
    "                    break\n",
    "    filtered_df = chunk.loc[chunk.index[selected_indexes]]\n",
    "    filtered_df.to_csv('data/filtered_data.csv', mode='a', header=False)\n",
    "    count += CHUNK_SIZE\n",
    "    print(\"processed one chunk\")\n",
    "print('finished data filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化\n",
    "\n",
    "1. 现在选的数据的周边数据很多都是可以用的，只不过有的需要补上trace"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittfenv20conda766c41579b2b4f15b06adf3d1d69eb2b",
   "display_name": "Python 3.7.7 64-bit ('tfenv20': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}